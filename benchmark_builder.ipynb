{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "This notebook builds a long context benchmark, as discussed by Federico, Arjun,\n",
    "Harm, and Leandro. Unlike typical Code LLM benchmarks, this is a test\n",
    "generation benchmark: we prompt the model with the implementation of a Python\n",
    "function (and its docstring), and ask for a test suite. The result is scored in\n",
    "two steps: if any test in the test suite fails, the score is zero. Otherwise,\n",
    "we the tests are scored based on their coverage of the funciton's\n",
    "implementation. To make the problem harder, we add several other functions to\n",
    "the prompt to serve as distractors. There are enough distractors to exercise\n",
    "models with very long context lengths (up to 128K tokens). We use two datasets:\n",
    "HumanEval and MultiPL-T. Both have several Python functions. The HumanEval\n",
    "functions should be decontaminated before training: their docstrings should not\n",
    "appear in the training data. The MultiPL-T functions are functions extracted\n",
    "from the Stack v1.2. Thus they are very likely to appear in models' training\n",
    "data, but they are merely distractors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "import random\n",
    "import os\n",
    "from typing import List\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# In case you're in an environment where you really want this to be set.\n",
    "print(os.getenv(\"HF_DATASETS_CACHE\"))\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "# This is likely an overestimate. But, it should be close enough and we don't need\n",
    "# to be exact.\n",
    "CHARS_PER_TOKEN = 2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset openai_humaneval (/home/elleven/.cache/huggingface/datasets/openai_humaneval/openai_humaneval/1.0.0/2955cebd73602e828fa8c0a424c594e5fab4ec863b316ca98f3d8fdb6a626e75)\n",
      "Found cached dataset parquet (/home/elleven/.cache/huggingface/datasets/nuprl___parquet/nuprl--stack-dedup-python-testgen-starcoder-filter-inferred-v2-8a147987b4874669/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "Found cached dataset parquet (/home/elleven/.cache/huggingface/datasets/nuprl___parquet/nuprl--humaneval-py-mutants-b940dfa114eb395a/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
     ]
    }
   ],
   "source": [
    "humaneval = datasets.load_dataset(\"openai_humaneval\", split=\"test\")\n",
    "# The MultiPL-T dataset is currently private, but will be public soon.\n",
    "multiplt = datasets.load_dataset(\"nuprl/stack-dedup-python-testgen-starcoder-filter-inferred-v2\", split=\"train\")\n",
    "# mutant generated dataset\n",
    "mutant_ds = datasets.load_dataset(\"nuprl/humaneval-py-mutants\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distractors(approximate_token_count: int) -> List[str]:\n",
    "    result = []\n",
    "    result_chars = 0\n",
    "    target_chars = int(approximate_token_count * CHARS_PER_TOKEN)\n",
    "    while result_chars < target_chars:\n",
    "        fn = random.choice(multiplt)[\"content\"]\n",
    "        result.append(fn)\n",
    "        result_chars += len(fn)\n",
    "    return result\n",
    "\n",
    "def find_mutant_with_idx(humaneval_problem_index: int):\n",
    "    for ex in mutant_ds:\n",
    "        if f\"_{humaneval_problem_index}_\" in ex[\"name\"]:\n",
    "            return ex\n",
    "    return None\n",
    "\n",
    "def build_prompt(\n",
    "        approximate_token_count: int,\n",
    "        humaneval_problem_index: int,\n",
    "        insert_where: str):\n",
    "    distractors = get_distractors(approximate_token_count)\n",
    "    target_problem = humaneval[humaneval_problem_index]\n",
    "    target_function = target_problem[\"prompt\"] + target_problem[\"canonical_solution\"]\n",
    "    if insert_where == \"first half\":\n",
    "        insert_index = random.randint(0, len(distractors) // 2)    \n",
    "    elif insert_where == \"second half\":\n",
    "        insert_index = random.randint(len(distractors) // 2, len(distractors))\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown insert_where: {insert_where}\")\n",
    "    distractors.insert(insert_index, target_function)\n",
    "    mutants = find_mutant_with_idx(humaneval_problem_index)[\"mutants\"]\n",
    "    mutants = mutants if mutants is not None else []\n",
    "    return { \n",
    "        \"prompt\": \"\\n\\n\".join(distractors),\n",
    "        \"target_function\": target_function,\n",
    "        \"humaneval_task_id\": target_problem[\"task_id\"],\n",
    "        \"task_id\": f\"LongBench_{target_problem['task_id']}_{approximate_token_count}_{insert_where}\",\n",
    "        \"approx_token_count\": approximate_token_count,\n",
    "        \"mutants\": mutants,\n",
    "        \"target_function_name\": target_problem[\"entry_point\"]\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Prompts\n",
    "\n",
    "Some examples of prompts that we can construct.\n",
    "\n",
    "With 0 as the number of target tokens, we get no distractors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "def add(x: int, y: int):\n",
      "    \"\"\"Add two numbers x and y\n",
      "    >>> add(2, 3)\n",
      "    5\n",
      "    >>> add(5, 7)\n",
      "    12\n",
      "    \"\"\"\n",
      "    return x + y\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(build_prompt(0, 53, \"first half\")[\"prompt\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With 400 target tokens, we get 1-2 distractors and the `where` argument starts to\n",
    "make sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "def add(x: int, y: int):\n",
      "    \"\"\"Add two numbers x and y\n",
      "    >>> add(2, 3)\n",
      "    5\n",
      "    >>> add(5, 7)\n",
      "    12\n",
      "    \"\"\"\n",
      "    return x + y\n",
      "\n",
      "\n",
      "def to_list(tup: tuple):\n",
      "    \"\"\"Convert from tuple to packed list\n",
      "\n",
      "    Allows us to call function with arguments in a loop\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    tup: tuple\n",
      "        tuple of objects to convert to packed list\n",
      "\n",
      "    Raises\n",
      "    ------\n",
      "    ValueError\n",
      "        If passed uneven number of arguments without a list. Please wrap your args in a list.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> to_list(([x1, x2, x3], [y1, y2, y3]))\n",
      "    [[x1, y1], [x2, y2], [x3, y3]]\n",
      "    >>> to_list(([x1], [y1]))\n",
      "    [[x1, y1]]\n",
      "    >>> to_list(([x1, x2, x3], ))\n",
      "    [[x1], [x2], [x3]]\n",
      "    >>> to_list((x1, ))\n",
      "    [[x1]]\n",
      "    >>> to_list((x1, y1))\n",
      "    [[x1, y1]]\n",
      "    >>> to_list((x1, x2, x3, y1, y2, y3))\n",
      "    [[x1, y1], [x2, y2], [x3, y3]]\n",
      "    \"\"\"\n",
      "    n_tup = len(tup)\n",
      "    if n_tup == 0:\n",
      "        return []\n",
      "    if not isinstance(tup[0], list):\n",
      "        # the first element is data\n",
      "        if n_tup == 1:\n",
      "            return [list(tup)]\n",
      "        if n_tup % 2 != 0:\n",
      "            raise ValueError('Don\\'t know how to handle uneven number of args '\n",
      "                             'without a list. Please wrap your args in a list.')\n",
      "        # assume first half of args is input and second half is outcome\n",
      "        return [list(el) for el in zip(tup[:(n_tup // 2)], tup[(n_tup // 2):])]\n",
      "    if n_tup == 1:\n",
      "        return [[x] for x in tup[0]]\n",
      "    n_mods = len(tup[0])\n",
      "    lists_packed = [[] for _ in range(n_mods)]\n",
      "    for i in range(n_mods):\n",
      "        for j in range(n_tup):\n",
      "            lists_packed[i].append(tup[j][i])\n",
      "    return lists_packed\n"
     ]
    }
   ],
   "source": [
    "print(build_prompt(400, 53, \"first half\")[\"prompt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def HEXtoVOLTS(ADChexStr):\n",
      "    \"\"\"ADC: 1000.0 volts full scale (D1B6).\n",
      "    (for scaling ADC input)\n",
      "    HEXtoVOLTS('D1B6') => 1000\n",
      "    HEXtoVOLTS('BCD4') =>  900 \"\"\"\n",
      "    return int(int(ADChexStr,16) / 53.686 + 0.5)\n",
      "\n",
      "def erathostenes_sieve(n: int) -> dict:\n",
      "    \"\"\"\n",
      "    1.6\n",
      "    Returns a dictionary containing prime numbers\n",
      "    It is not recommended to use a list (1) because of\n",
      "    reallocation and (2) because of index handling : the prime\n",
      "    numbers start at 2 and the list, 0; and because some numbers\n",
      "    are removed, the index changes too\n",
      "    \"\"\"\n",
      "    if n <= 0: raise ValueError(\"Argument can't be <= 0\")\n",
      "\n",
      "    primes = {n:None for n in range(2, n + 1)}\n",
      "\n",
      "    # We must convert it as a list, because the size changes\n",
      "    for prime in list(primes.keys()):\n",
      "        for number in list(primes.keys()):\n",
      "            # It is a composit number if it is a multiple of the prime\n",
      "            if prime != number and number%prime == 0:\n",
      "                del primes[number]\n",
      "\n",
      "    return primes\n",
      "\n",
      "def kewley_agn_oi(log_oi_ha):\n",
      "    \"\"\"Seyfert/LINER classification line for log([OI]/Ha).\"\"\"\n",
      "    return 1.18 * log_oi_ha + 1.30\n",
      "\n",
      "\n",
      "\n",
      "def add(x: int, y: int):\n",
      "    \"\"\"Add two numbers x and y\n",
      "    >>> add(2, 3)\n",
      "    5\n",
      "    >>> add(5, 7)\n",
      "    12\n",
      "    \"\"\"\n",
      "    return x + y\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(build_prompt(400, 53, \"second half\")[\"prompt\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Benchmark\n",
    "\n",
    "There are a number of trivial problems in HumanEval, such as #53 shown above.\n",
    "We want a subset of problems that have a range of difficulties. The following\n",
    "ten problems have varying difficulty in several programming languages\n",
    "and were picked by Francesca Lucchetti for MultiPL-T.\n",
    "\n",
    "- HumanEval_100_make_a_pile\n",
    "- HumanEval_13_greatest_common_divisor\n",
    "- HumanEval_152_compare\n",
    "- HumanEval_157_right_angle_triangle\n",
    "- HumanEval_27_flip_case\n",
    "- HumanEval_40_triples_sum_to_zero\n",
    "- HumanEval_55_fib\n",
    "- HumanEval_66_digitSum\n",
    "- HumanEval_72_will_it_fly\n",
    "- HumanEval_74_total_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['prompt', 'target_function', 'humaneval_task_id', 'task_id', 'approx_token_count', 'mutants', 'target_function_name'],\n",
       "    num_rows: 80\n",
       "})"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "APPROXIMATE_TOKEN_COUNTS = [0, 8_000, 64_000, 128_000]\n",
    "HUMANEVAL_PROBLEM_INDICES = [100, 13, 152, 157, 27, 40, 55, 66, 72, 74]\n",
    "INSERT_WHERES = [ \"first half\", \"second half\"]\n",
    "\n",
    "benchmark = datasets.Dataset.from_list(\n",
    "    [build_prompt(*x) for x in itertools.product(APPROXIMATE_TOKEN_COUNTS, HUMANEVAL_PROBLEM_INDICES, INSERT_WHERES)])\n",
    "benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating json from Arrow format: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 18.82ba/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10971445"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark.to_json(\"benchmark.jsonl\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prompt': '\\ndef make_a_pile(n):\\n    \"\"\"\\n    Given a positive integer n, you have to make a pile of n levels of stones.\\n    The first level has n stones.\\n    The number of stones in the next level is:\\n        - the next odd number if n is odd.\\n        - the next even number if n is even.\\n    Return the number of stones in each level in a list, where element at index\\n    i represents the number of stones in the level (i+1).\\n\\n    Examples:\\n    >>> make_a_pile(3)\\n    [3, 5, 7]\\n    \"\"\"\\n    return [n + 2*i for i in range(n)]\\n',\n",
       " 'target_function': '\\ndef make_a_pile(n):\\n    \"\"\"\\n    Given a positive integer n, you have to make a pile of n levels of stones.\\n    The first level has n stones.\\n    The number of stones in the next level is:\\n        - the next odd number if n is odd.\\n        - the next even number if n is even.\\n    Return the number of stones in each level in a list, where element at index\\n    i represents the number of stones in the level (i+1).\\n\\n    Examples:\\n    >>> make_a_pile(3)\\n    [3, 5, 7]\\n    \"\"\"\\n    return [n + 2*i for i in range(n)]\\n',\n",
       " 'humaneval_task_id': 'HumanEval/100',\n",
       " 'task_id': 'LongBench_HumanEval/100_0_first half',\n",
       " 'approx_token_count': 0,\n",
       " 'mutants': ['from typing import List\\n\\ndef make_a_pile(n: int) -> List[int]:\\n    \"\"\"\\n    Given a positive integer n, you have to make a pile of n levels of stones.\\n    The first level has n stones.\\n    The number of stones in the next level is:\\n        - the next odd number if n is odd.\\n        - the next even number if n is even.\\n    Return the number of stones in each level in a list, where element at index\\n    i represents the number of stones in the level (i+1).\\n\\n    Examples:\\n    >>> make_a_pile(3)\\n    [3, 5, 7]\\n    \"\"\"\\n\\n    result = [n]\\n    while n > 1:\\n        n = n // 2 if n % 2 else n // 2 + 1\\n        result.append(n)\\n    return result[::-1]',\n",
       "  'from typing import List\\n\\ndef make_a_pile(n: int) -> List[int]:\\n    \"\"\"\\n    Given a positive integer n, you have to make a pile of n levels of stones.\\n    The first level has n stones.\\n    The number of stones in the next level is:\\n        - the next odd number if n is odd.\\n        - the next even number if n is even.\\n    Return the number of stones in each level in a list, where element at index\\n    i represents the number of stones in the level (i+1).\\n\\n    Examples:\\n    >>> make_a_pile(3)\\n    [3, 5, 7]\\n    \"\"\"\\n\\n    if n < 1:\\n        raise ValueError(\"The number of stones cannot be less than one.\")\\n\\n    arr = []\\n    curr = n\\n    for i in range(1, n + 1):\\n        arr.append(curr)\\n        if curr % 2 == 0:\\n            curr = curr + 1\\n        else:\\n            curr = curr + 2\\n    return arr'],\n",
       " 'target_function_name': 'make_a_pile'}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
